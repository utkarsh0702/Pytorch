{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch6_Character_wise_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBSAtL/JJfN08VALuwI2oW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarsh0702/Pytorch/blob/master/PyTorch6_Character_wise_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpHT3yMnQkkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HusUH_k9Rsqd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14931072-afa3-4d7a-8e78-7a04fdf9c06b"
      },
      "source": [
        "with open('Anna Karenina.txt', 'r') as f:\n",
        "  text=f.read()\n",
        "text[:100]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chapter 1\\nHappy families are all alike; every unhappy family is unhappy in its own way.\\n\\nEverything '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcMP8vEPS0aG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b6dc7361-5cfe-48ef-97a8-8e5992c36c30"
      },
      "source": [
        "#Tokenization\n",
        "chars= tuple(set(text))\n",
        "int2char= dict(enumerate(chars))\n",
        "char2int= {ch:i for i, ch in int2char.items()}\n",
        "\n",
        "#Encode the text\n",
        "encoded = np.array([char2int[ch] for ch in text])\n",
        "encoded[:100]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([74, 29, 32,  5, 73, 68, 30, 55, 60,  7, 26, 32,  5,  5,  2, 55, 34,\n",
              "       32, 28, 23, 66, 23, 68, 25, 55, 32, 30, 68, 55, 32, 66, 66, 55, 32,\n",
              "       66, 23,  8, 68, 12, 55, 68, 46, 68, 30,  2, 55, 21,  9, 29, 32,  5,\n",
              "        5,  2, 55, 34, 32, 28, 23, 66,  2, 55, 23, 25, 55, 21,  9, 29, 32,\n",
              "        5,  5,  2, 55, 23,  9, 55, 23, 73, 25, 55, 41, 16,  9, 55, 16, 32,\n",
              "        2, 65,  7,  7, 20, 46, 68, 30,  2, 73, 29, 23,  9,  6, 55])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rL8Or-bT6A8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "43aaf4a8-613d-454f-b841-f52cb2234f58"
      },
      "source": [
        "#Data Preprocessing\n",
        "def one_hot_encode(arr,n_labels):\n",
        "  one_hot= np.zeros((np.multiply(*arr.shape), n_labels), dtype= np.float32)\n",
        "  one_hot[np.arange(one_hot.shape[0]), arr.flatten()]=1\n",
        "  one_hot= one_hot.reshape((*arr.shape, n_labels))\n",
        "  return one_hot\n",
        "\n",
        "#Checking one hot encoder\n",
        "test_seq= np.array([[3,5,1]])\n",
        "one_hot= one_hot_encode(test_seq, 8)\n",
        "print(one_hot)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "  [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            "  [0. 1. 0. 0. 0. 0. 0. 0.]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9S3hQ62VYIP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f7a336f0-34f2-4dad-a767-914bfc0cba14"
      },
      "source": [
        "#defining the batchs and sequences\n",
        "def get_batches(arr, batch_size, seq_length):\n",
        "  batch_size_total= batch_size*seq_length\n",
        "  n_batches= len(arr)//batch_size_total\n",
        "\n",
        "  arr= arr[:n_batches*batch_size_total]\n",
        "  arr= arr.reshape((batch_size,-1))\n",
        "\n",
        "  for n in range(0, arr.shape[1],seq_length):\n",
        "    x= arr[:,n:n+seq_length]\n",
        "    y= np.zeros_like(x)\n",
        "    try:\n",
        "      y[:,:-1],y[:,-1]= x[:,1:], arr[:,n+seq_length]\n",
        "    except IndexError:\n",
        "      y[:,:-1],y[:,-1]= x[:,1:], arr[:,0]\n",
        "    \n",
        "    yield x,y\n",
        "\n",
        "batches= get_batches(encoded, 8,50)\n",
        "x,y= next(batches)\n",
        "\n",
        "print('X\\n', x[:10,:10])\n",
        "print('Y\\n', y[:10,:10])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X\n",
            " [[74 29 32  5 73 68 30 55 60  7]\n",
            " [76 55 76 23 25 39 41  9 25 41]\n",
            " [16  9 55 29 41 21 25 68 55 25]\n",
            " [ 2 41  9 68 55 16 32 25 55 33]\n",
            " [66 68 55 25 28 23 66 68 71 55]\n",
            " [68 55 32  9 76 55 76 68 32 73]\n",
            " [55 29 32 76 55 23 28 32  6 23]\n",
            " [ 9 65 55 62 42 30 68 55 73 29]]\n",
            "Y\n",
            " [[29 32  5 73 68 30 55 60  7 26]\n",
            " [55 76 23 25 39 41  9 25 41 66]\n",
            " [ 9 55 29 41 21 25 68 55 25 29]\n",
            " [41  9 68 55 16 32 25 55 33 21]\n",
            " [68 55 25 28 23 66 68 71 55 32]\n",
            " [55 32  9 76 55 76 68 32 73 29]\n",
            " [29 32 76 55 23 28 32  6 23  9]\n",
            " [65 55 62 42 30 68 55 73 29 68]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8MRRIEjYcI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining the model\n",
        "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class CharRNN(nn.Module):\n",
        "  def __init__(self, tokens, n_hidden=255, n_layers=2, drop_prob=0.5, lr=0.001):\n",
        "    super().__init__()\n",
        "    self.n_hidden= n_hidden\n",
        "    self.n_layers= n_layers\n",
        "    self.drop_prob= drop_prob\n",
        "    self.lr= lr\n",
        "\n",
        "    #Creating character dictonary\n",
        "    self.chars= tokens\n",
        "    self.int2char= dict(enumerate(self.chars))\n",
        "    self.char2int= {ch:i for i, ch in self.int2char.items()}\n",
        "\n",
        "    #Layers\n",
        "    self.lstm= nn.LSTM(len(self.chars), n_hidden, n_layers, dropout= drop_prob, batch_first= True)\n",
        "    self.dropout= nn.Dropout(drop_prob)\n",
        "    self.fc= nn.Linear(n_hidden, len(self.chars))\n",
        "  \n",
        "  def forward(self, x, hidden):\n",
        "    r_output, hidden= self.lstm(x, hidden)\n",
        "    out= self.dropout(r_output)\n",
        "    out= out.view(-1, self.n_hidden)\n",
        "    out= self.fc(out)\n",
        "    return out, hidden\n",
        "  \n",
        "  def init_hidden(self, batch_size):\n",
        "    weight= next(self.parameters()).data\n",
        "    hidden=(weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda(), weight.new(self.n_layers, batch_size, self.n_hidden).zero_().cuda())\n",
        "    return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0stXQ8ncX47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, data, epochs=10, batch_size=10, seq_length=50, lr=0.001, clip=5, val_frac=0.1, print_every=10):\n",
        "  net.train()\n",
        "  opt= torch.optim.Adam(net.parameters(), lr=lr)\n",
        "  loss_function= nn.CrossEntropyLoss()\n",
        "  net.to(device)\n",
        "  val_idx= int(len(data)*(1-val_frac))\n",
        "  data, val_data= data[:val_idx], data[val_idx:]\n",
        "  counter=0\n",
        "  n_chars=len(net.chars)\n",
        "\n",
        "  for e in range(epochs):\n",
        "    counter=0\n",
        "    h= net.init_hidden(batch_size)\n",
        "    for x,y in get_batches(data, batch_size, seq_length):\n",
        "      counter+=1\n",
        "      x= one_hot_encode(x, n_chars)\n",
        "      inputs, targets= torch.from_numpy(x), torch.from_numpy(y)\n",
        "      inputs, targets= inputs.to(device), targets.to(device)\n",
        "      h= tuple([each.data for each in h])\n",
        "      net.zero_grad()\n",
        "      output, h= net(inputs, h)\n",
        "\n",
        "      loss= loss_function(output, targets.view(batch_size*seq_length))\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "      opt.step()\n",
        "      if counter%print_every==0:\n",
        "        val_h= net.init_hidden(batch_size)\n",
        "        val_losses=[]\n",
        "        net.eval()\n",
        "        for x,y in get_batches(val_data, batch_size, seq_length):\n",
        "          x= one_hot_encode(x, n_chars)\n",
        "          inputs, targets= torch.from_numpy(x), torch.from_numpy(y)\n",
        "          inputs, targets= inputs.to(device), targets.to(device)\n",
        "          val_h= tuple([each.data for each in val_h])\n",
        "          output, val_h= net(inputs, val_h)\n",
        "          val_loss= loss_function(output, targets.view(batch_size*seq_length))\n",
        "          val_losses.append(val_loss.item())\n",
        "        net.train()\n",
        "        print(\"Epochs: {}/{}.....\".format(e+1, epochs), \"Steps: {}.....\".format(counter), \"Loss: {}.....\".format(loss.item()), \"Val Loss: {}......\".format(np.mean(val_losses)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Catlg8kiN3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "61711665-1c19-4714-f3fc-5edbac1a3b4c"
      },
      "source": [
        "#Define and print the model\n",
        "n_hidden=512\n",
        "n_layers=2\n",
        "net= CharRNN(chars, n_hidden, n_layers)\n",
        "print(net)\n",
        "\n",
        "batch_size= 128\n",
        "seq_length= 100\n",
        "n_epochs=20\n",
        "train(net, encoded, epochs= n_epochs, batch_size= batch_size, seq_length= seq_length,lr=0.001, clip=5, val_frac=0.1, print_every=10 )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CharRNN(\n",
            "  (lstm): LSTM(78, 512, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=78, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-PYdTjxjVhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}